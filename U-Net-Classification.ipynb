{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net by Lukas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    " \n",
    "from tqdm import tqdm \n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.util import random_noise\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "\n",
    "from keras import layers, metrics\n",
    "\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experiment setup and the HParams experiment summary\n",
    "\n",
    "Experiment with three hyperparameters in the model:\n",
    "\n",
    "1. Number of channels (1x or 2x)\n",
    "2. Learning rate\n",
    "3. Batch size\n",
    "4. Epochs\n",
    "5. Picture size\n",
    "6. (Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"24_05_18\"\n",
    "\n",
    "\n",
    "# HP_CHANNELS = hp.HParam('channels', hp.Discrete([1, 2]))\n",
    "# HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([0.00005, 0.0001, 0.0005, 0.001])) #hp.RealInterval(0.0001, 0.01))  \n",
    "# HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([10, 30, 50, 100]))\n",
    "# HP_EPOCHS = hp.HParam('epochs', hp.Discrete([100]))\n",
    "# HP_IMAGE_SIZE = hp.HParam('image_size', hp.Discrete([1]))\n",
    "# # HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "# METRIC_F1SCORE = 'f1_score'\n",
    "\n",
    "# with tf.summary.create_file_writer(f'logs/hparam_tuning_{date}').as_default(): #_24_04_17\n",
    "#   hp.hparams_config(\n",
    "#     hparams=[HP_CHANNELS, HP_LEARNING_RATE, HP_BATCH_SIZE, HP_EPOCHS, HP_IMAGE_SIZE],\n",
    "#     metrics=[hp.Metric(METRIC_F1SCORE, display_name='Jaccard Score')],\n",
    "#   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(8, 8))\n",
    "\n",
    "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    if i == 1:\n",
    "      plt.imshow(display_list[i], cmap='gray',  interpolation='nearest')\n",
    "    elif i == 2:\n",
    "      plt.imshow(display_list[i], cmap='jet',  interpolation='nearest')\n",
    "    else:\n",
    "      plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "    plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2332/2332 [01:02<00:00, 37.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing test images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:26<00:00, 38.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is ready\n",
      "873151\n",
      "{0.0: 54791489, 1.0: 873151}\n",
      "Percentage of faulty images in train data: 1.568591838553164  %\n"
     ]
    }
   ],
   "source": [
    "hyper_param_channels = 2\n",
    "hyper_param_learning_rate = 0.001\n",
    "hyper_param_batch_size = 100\n",
    "hyper_param_epochs = 70\n",
    "hyper_param_image_size = 1\n",
    "\n",
    "#image dimensions, seems to work with non-square inputs\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "IMAGE_HEIGHT =  192*hyper_param_image_size\n",
    "IMAGE_WIDTH = 64*hyper_param_image_size\n",
    "\n",
    "seed = 4\n",
    "np.random.seed = seed\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "DATA_TRAIN = \"./datasets/KolektorSDD2/train/\"\n",
    "DATA_TEST = \"./datasets/KolektorSDD2/test/\"\n",
    "\n",
    "\n",
    "\n",
    "train_ids = next(os.walk(os.path.join(DATA_TRAIN, \"images/\")))[2]\n",
    "test_ids = next(os.walk(os.path.join(DATA_TEST, \"images/\")))[2]\n",
    "\n",
    "damaged = [] # prepare for data augmentation\n",
    "damaged_mask = []\n",
    "\n",
    "X_train = np.zeros((len(train_ids), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.float16)\n",
    "y_train = np.zeros((len(train_ids), IMAGE_HEIGHT, IMAGE_WIDTH), dtype=np.float16)\n",
    "\n",
    "print('Resizing training images and masks')\n",
    "\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   \n",
    "    path = DATA_TRAIN \n",
    "\n",
    "    img = imread(path + 'images/' + id_)[:,:,:IMAGE_CHANNELS]  \n",
    "    img = resize(img, (IMAGE_HEIGHT, IMAGE_WIDTH), mode='constant', preserve_range=True)\n",
    "    img /= 255.0\n",
    "    X_train[n] = img  #Fill empty X_train with values from img\n",
    "\n",
    "    mask = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, 1), dtype=bool)\n",
    "    mask_file = os.path.join(path + 'masks/' + id_[:5] + \"_GT.png\")\n",
    "    mask = imread(mask_file)[:,:]\n",
    "\n",
    "    mask = resize(mask, (IMAGE_HEIGHT, IMAGE_WIDTH), mode='constant', preserve_range=True)\n",
    "    mask /= 255.0  \n",
    "    mask = np.where(mask > 0.5, 1.0, 0.0) \n",
    "    y_train[n] = mask \n",
    "\n",
    "    if np.count_nonzero(mask) != 0:\n",
    "        damaged.append(img)\n",
    "        damaged_mask.append(mask)\n",
    "    \n",
    "# test images\n",
    "test_images = np.zeros((len(test_ids), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.float16)\n",
    "test_masks = np.zeros((len(test_ids), IMAGE_HEIGHT, IMAGE_WIDTH), dtype=np.float16)\n",
    "\n",
    "sizes_test = []\n",
    "print('Resizing test images') \n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = DATA_TEST\n",
    "    img = imread(path + '/images/' + id_ )[:,:,:IMAGE_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMAGE_HEIGHT, IMAGE_WIDTH), mode='constant', preserve_range=True)\n",
    "    img /= 255.0\n",
    "    test_images[n] = img\n",
    "\n",
    "    mask = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, 1), dtype=bool)\n",
    "    mask_file = os.path.join(path + 'masks/' + id_[:5] + \"_GT.png\")\n",
    "    mask = imread(mask_file)[:,:]\n",
    "\n",
    "    mask = resize(mask, (IMAGE_HEIGHT, IMAGE_WIDTH), mode='constant', preserve_range=True)\n",
    "    mask /= 255.0     \n",
    "    mask = np.where(mask > 0.5, 1.0, 0.0)   \n",
    "    test_masks[n] = mask \n",
    "\n",
    "## Data augmentation - rotate and flip images\n",
    "vertical_train = np.flip(damaged, axis=0)\n",
    "vertical_test = np.flip(damaged_mask, axis=0)\n",
    "\n",
    "horizontal_train = np.flip(damaged, axis=1)\n",
    "horizontal_test = np.flip(damaged_mask, axis=1)\n",
    "\n",
    "rotating_train = np.rot90(damaged, k=2)\n",
    "rotating_test = np.rot90(damaged_mask, k=2)\n",
    "\n",
    "vert_rot_train = np.rot90(vertical_train, k=2)\n",
    "vert_rot_test = np.rot90(vertical_test, k=2)\n",
    "\n",
    "hor_rot_train = np.rot90(horizontal_train, k=2)\n",
    "hor_rot_test = np.rot90(horizontal_test, k=2)\n",
    "\n",
    "# Done with rotation\n",
    "Boxes = []\n",
    "check = []\n",
    "for img in damaged_mask:\n",
    "    labels = label(img)\n",
    "    regions = regionprops(labels)\n",
    "    if len(regions) == 1:\n",
    "        check.append(1)\n",
    "        for props in regions:\n",
    "            min_x, min_y, max_x, max_y = props.bbox\n",
    "            Boxes.append((min_x, min_y, max_x, max_y))\n",
    "    else:\n",
    "        check.append(0)\n",
    "\n",
    "# Throw out images, which have more than one damage\n",
    "onedamage = [damaged[i] for i in range(len(damaged)) if check[i] == 1]\n",
    "onedamage_mask = [damaged_mask[i] for i in range(len(damaged_mask)) if check[i] == 1]\n",
    "\n",
    "def crop_image(image, bbox):\n",
    "    # Crop the image using NumPy array slicing\n",
    "    cropped_image = image[bbox[0]:bbox[2], bbox[1]:bbox[3]]\n",
    "    return cropped_image\n",
    "\n",
    "def overlay_image(background, background_mask, overlay, overlay_mask):\n",
    "    # Generate random position for overlay image\n",
    "    if overlay.shape[1] < background.shape[1]:\n",
    "        x_offset = np.random.randint(0, background.shape[1] - overlay.shape[1])\n",
    "        y_offset = np.random.randint(0, background.shape[0] - overlay.shape[0])\n",
    "    \n",
    "        # Overlay the image\n",
    "        background[y_offset:y_offset + overlay.shape[0], x_offset:x_offset + overlay.shape[1]] = overlay\n",
    "        background_mask[y_offset:y_offset + overlay_mask.shape[0], x_offset:x_offset + overlay_mask.shape[1]] = overlay_mask\n",
    "        return background, background_mask\n",
    "    else:\n",
    "        return background, background_mask\n",
    "\n",
    "generated_img = np.empty((len(onedamage),IMAGE_HEIGHT,IMAGE_WIDTH,3))\n",
    "generated_mask = np.empty((len(onedamage), IMAGE_HEIGHT,IMAGE_WIDTH))\n",
    "overlayed_indices = []\n",
    "for i, image in enumerate(onedamage):\n",
    "    # Get the bounding box for the current image\n",
    "    bbox = Boxes[i]\n",
    "    mask = onedamage_mask[i]\n",
    "    # Crop the image\n",
    "    cropped_image = crop_image(image, bbox)\n",
    "    cropped_mask = crop_image(mask, bbox)\n",
    "    # Pick a random overlay image from the list\n",
    "    overlay_image_index = np.random.choice([idx for idx in range(len(X_train)) if idx not in overlayed_indices])\n",
    "    overlay = X_train[overlay_image_index]\n",
    "    overlay_mask = y_train[overlay_image_index]\n",
    "\n",
    "    # Overlay the cropped image onto the random overlay image\n",
    "    new_image, new_mask = overlay_image(overlay, overlay_mask, cropped_image, cropped_mask)\n",
    "    generated_img[i] = new_image\n",
    "    generated_mask[i] = new_mask\n",
    "    overlayed_indices.append(overlay_image_index)\n",
    "\n",
    "noised = np.empty_like(damaged)\n",
    "noised_mask = damaged_mask\n",
    "i = 0\n",
    "for img in damaged:\n",
    "    noise = random_noise(img, mode='gaussian', rng=seed, clip=True)\n",
    "    noised[i] = noise\n",
    "    i = i+1\n",
    "\n",
    "noised_vert = np.empty_like(damaged)\n",
    "noised_mask_vert = vertical_test\n",
    "i = 0\n",
    "for img in vertical_train:\n",
    "    noise = random_noise(img, mode='gaussian', rng=seed, clip=True)\n",
    "    noised_vert[i] = noise\n",
    "    i = i+1\n",
    "\n",
    "noised_horr = np.empty_like(damaged)\n",
    "noised_mask_horr = horizontal_test\n",
    "i = 0\n",
    "for img in horizontal_train:\n",
    "    noise = random_noise(img, mode='gaussian', rng=seed, clip=True)\n",
    "    noised_horr[i] = noise\n",
    "    i = i+1\n",
    "\n",
    "X_train = np.concatenate((vertical_train, horizontal_train, rotating_train, vert_rot_train, hor_rot_train, X_train, noised, noised_vert, noised_horr, generated_img))\n",
    "y_train = np.concatenate((vertical_test, horizontal_test, rotating_test, vert_rot_test, hor_rot_test, y_train, noised_mask, noised_mask_vert, noised_mask_horr, generated_mask))\n",
    "\n",
    "# X_train = np.concatenate((vertical_train, horizontal_train, rotating_train, vert_rot_train, hor_rot_train, X_train, noised, noised_vert, noised_horr))\n",
    "# y_train = np.concatenate((vertical_test, horizontal_test, rotating_test, vert_rot_test, hor_rot_test, y_train, noised_mask, noised_mask_vert, noised_mask_horr))\n",
    "\n",
    "\n",
    "# X_train = np.concatenate((vertical_train, horizontal_train, rotating_train, vert_rot_train, hor_rot_train, X_train))\n",
    "# y_train = np.concatenate((vertical_test, horizontal_test, rotating_test, vert_rot_test, hor_rot_test, y_train))\n",
    "\n",
    "\n",
    "print('Dataset is ready')\n",
    "\n",
    "non_zero = np.count_nonzero(y_train)\n",
    "print(non_zero)\n",
    "# print(non_zero/(IMAGE_HEIGHT*IMAGE_WIDTH*len(y_train))*100)\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print(dict(zip(unique, counts)))\n",
    "print(\"Percentage of faulty images in train data:\", counts[1]/(counts[0]+counts[1])*100, \" %\")\n",
    "neg = counts[0]\n",
    "pos = counts[1]\n",
    "\n",
    "initial_bias = np.log([pos/neg])\n",
    "output_bias = tf.keras.initializers.Constant(initial_bias)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.3, random_state = seed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = np.array([1 if np.count_nonzero(element) != 0 else 0 for element in y_train])\n",
    "y_val_bin = np.array([1 if np.count_nonzero(element) != 0 else 0 for element in y_val])\n",
    "test_masks_bin = np.array([1 if np.count_nonzero(element) != 0 else 0 for element in test_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(y_val_bin)); print(len(y_val))\n",
    "# print(\"y_train_bin:\\n\", y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 192, 64, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 192, 64, 32)  896         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 192, 64, 32)  9248        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 96, 32, 32)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 96, 32, 64)   18496       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 96, 32, 64)   36928       ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 48, 16, 64)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 48, 16, 128)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 48, 16, 128)  147584      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 24, 8, 128)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 24, 8, 256)   295168      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 24, 8, 256)   590080      ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 12, 4, 256)  0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 12, 4, 512)   1180160     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 12, 4, 512)   2359808     ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 24, 8, 256)  524544      ['conv2d_9[0][0]']               \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 24, 8, 512)   0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 24, 8, 256)   1179904     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 24, 8, 256)   590080      ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 48, 16, 128)  131200     ['conv2d_11[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 48, 16, 256)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 48, 16, 128)  295040      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 48, 16, 128)  147584      ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 96, 32, 64)  32832       ['conv2d_13[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 96, 32, 128)  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 96, 32, 64)   73792       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 96, 32, 64)   36928       ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 192, 64, 32)  8224       ['conv2d_15[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 192, 64, 64)  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 192, 64, 32)  18464       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 192, 64, 32)  9248        ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 192, 64, 1)   33          ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,760,097\n",
      "Trainable params: 7,760,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 192, 64, 3)]      0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 192, 64, 1)        7760097   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 192, 64, 1)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12288)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1572992   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,333,218\n",
      "Trainable params: 1,573,121\n",
      "Non-trainable params: 7,760,097\n",
      "_________________________________________________________________\n",
      "Epoch 1/70\n",
      "31/31 [==============================] - 10s 125ms/step - loss: 0.3469 - accuracy: 0.9332 - val_loss: 0.3127 - val_accuracy: 0.9551\n",
      "Epoch 2/70\n",
      "31/31 [==============================] - 3s 71ms/step - loss: 0.2881 - accuracy: 0.9808 - val_loss: 0.2908 - val_accuracy: 0.9654\n",
      "Epoch 3/70\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 0.2606 - accuracy: 0.9896 - val_loss: 0.2639 - val_accuracy: 0.9669\n",
      "Epoch 4/70\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 0.2209 - accuracy: 0.9893 - val_loss: 0.2332 - val_accuracy: 0.9706\n",
      "Epoch 5/70\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 0.1885 - accuracy: 0.9909 - val_loss: 0.2014 - val_accuracy: 0.9735\n",
      "Epoch 6/70\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 0.1517 - accuracy: 0.9889 - val_loss: 0.1658 - val_accuracy: 0.9684\n",
      "Epoch 7/70\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 0.1145 - accuracy: 0.9876 - val_loss: 0.1374 - val_accuracy: 0.9691\n",
      "Epoch 8/70\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.0834 - accuracy: 0.9893 - val_loss: 0.1187 - val_accuracy: 0.9698\n",
      "Epoch 9/70\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.0637 - accuracy: 0.9899 - val_loss: 0.1101 - val_accuracy: 0.9691\n",
      "Epoch 10/70\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.0564 - accuracy: 0.9886 - val_loss: 0.1082 - val_accuracy: 0.9706\n",
      "Epoch 11/70\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0468 - accuracy: 0.9896 - val_loss: 0.1085 - val_accuracy: 0.9706\n",
      "Epoch 12/70\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0464 - accuracy: 0.9889 - val_loss: 0.1105 - val_accuracy: 0.9691\n",
      "Epoch 13/70\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.0441 - accuracy: 0.9899 - val_loss: 0.1131 - val_accuracy: 0.9698\n",
      "Epoch 14/70\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0437 - accuracy: 0.9889 - val_loss: 0.1154 - val_accuracy: 0.9698\n",
      "Epoch 15/70\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0387 - accuracy: 0.9919 - val_loss: 0.1177 - val_accuracy: 0.9706\n",
      "Epoch 16/70\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 0.1211 - val_accuracy: 0.9720\n",
      "Epoch 17/70\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0384 - accuracy: 0.9915 - val_loss: 0.1229 - val_accuracy: 0.9735\n",
      "Epoch 18/70\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0405 - accuracy: 0.9906 - val_loss: 0.1249 - val_accuracy: 0.9713\n",
      "Epoch 19/70\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.0379 - accuracy: 0.9922 - val_loss: 0.1282 - val_accuracy: 0.9713\n",
      "Epoch 20/70\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0382 - accuracy: 0.9915 - val_loss: 0.1299 - val_accuracy: 0.9713\n",
      "Epoch 21/70\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0390 - accuracy: 0.9915 - val_loss: 0.1324 - val_accuracy: 0.9713\n",
      "Epoch 22/70\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0369 - accuracy: 0.9925 - val_loss: 0.1348 - val_accuracy: 0.9713\n",
      "Epoch 23/70\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0288 - accuracy: 0.9948 - val_loss: 0.1374 - val_accuracy: 0.9713\n",
      "Epoch 24/70\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0375 - accuracy: 0.9922 - val_loss: 0.1399 - val_accuracy: 0.9713\n",
      "Epoch 25/70\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0391 - accuracy: 0.9912 - val_loss: 0.1406 - val_accuracy: 0.9735\n",
      "Epoch 26/70\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0378 - accuracy: 0.9919 - val_loss: 0.1419 - val_accuracy: 0.9735\n",
      "Epoch 27/70\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0328 - accuracy: 0.9932 - val_loss: 0.1433 - val_accuracy: 0.9735\n",
      "Epoch 28/70\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.0334 - accuracy: 0.9932 - val_loss: 0.1465 - val_accuracy: 0.9720\n",
      "Epoch 29/70\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0370 - accuracy: 0.9919 - val_loss: 0.1474 - val_accuracy: 0.9713\n",
      "Epoch 30/70\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.0360 - accuracy: 0.9922 - val_loss: 0.1490 - val_accuracy: 0.9713\n",
      "Epoch 31/70\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0346 - accuracy: 0.9928 - val_loss: 0.1521 - val_accuracy: 0.9698\n",
      "Epoch 32/70\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0341 - accuracy: 0.9925 - val_loss: 0.1550 - val_accuracy: 0.9698\n",
      "Epoch 33/70\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0332 - accuracy: 0.9929 - val_loss: 0.1565 - val_accuracy: 0.9691\n",
      "Epoch 34/70\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.0336 - accuracy: 0.9928 - val_loss: 0.1582 - val_accuracy: 0.9691\n",
      "Epoch 35/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9919Restoring model weights from the end of the best epoch: 10.\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.0369 - accuracy: 0.9919 - val_loss: 0.1608 - val_accuracy: 0.9691\n",
      "Epoch 35: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# #Building U-net model\n",
    "# #Downward stream\n",
    "# inputs = tf.keras.layers.Input((IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))\n",
    "# conv_11 = layers.Conv2D(16*hyper_param_channels,kernel_size=(3,3), activation = 'relu', padding= 'same',kernel_initializer = 'he_normal')(inputs)\n",
    "# conv_12 = layers.Conv2D(16*hyper_param_channels,kernel_size=(3,3), activation = 'relu', padding= 'same',kernel_initializer = 'he_normal')(conv_11)#TODO: Understand parameters\n",
    "\n",
    "# max_pool_1 = layers.MaxPool2D((2,2))(conv_12)\n",
    "# conv_21 = layers.Conv2D(32*hyper_param_channels,(3,3),activation = 'relu',padding= 'same',kernel_initializer = 'he_normal')(max_pool_1)\n",
    "# conv_22 = layers.Conv2D(32*hyper_param_channels,(3,3),activation = 'relu', padding= 'same',kernel_initializer = 'he_normal')(conv_21)\n",
    "\n",
    "# max_pool_2 = layers.MaxPool2D((2,2))(conv_22)\n",
    "# conv_31 = layers.Conv2D(64*hyper_param_channels,(3,3),activation = 'relu', padding= 'same',kernel_initializer = 'he_normal')(max_pool_2)\n",
    "# conv_32 = layers.Conv2D(64*hyper_param_channels,(3,3),activation = 'relu', padding= 'same',kernel_initializer = 'he_normal')(conv_31)\n",
    "\n",
    "# max_pool_3 = layers.MaxPool2D((2,2))(conv_32)\n",
    "# conv_41 = layers.Conv2D(128*hyper_param_channels,(3,3),activation = 'relu', padding= 'same',kernel_initializer = 'he_normal')(max_pool_3)\n",
    "# conv_42 = layers.Conv2D(128*hyper_param_channels,(3,3),activation = 'relu', padding= 'same')(conv_41)\n",
    "\n",
    "# max_pool_4 = layers.MaxPool2D((2,2))(conv_42)\n",
    "# conv_51 = layers.Conv2D(256*hyper_param_channels,(3,3),activation = 'relu', padding= 'same',kernel_initializer = 'he_normal')(max_pool_4)\n",
    "# conv_52 = layers.Conv2D(256*hyper_param_channels,(3,3),activation = 'relu', padding= 'same',kernel_initializer = 'he_normal')(conv_51)\n",
    "\n",
    "# #Upward stream\n",
    "# upconv_1 = layers.Conv2DTranspose(128*hyper_param_channels,(2,2), strides=(2,2))(conv_52)\n",
    "# upconv_1_conc = layers.concatenate([upconv_1,conv_42])\n",
    "# conv_61 = layers.Conv2D(128*hyper_param_channels,(3,3),activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(upconv_1_conc)\n",
    "# conv_62 = layers.Conv2D(128*hyper_param_channels,(3,3),activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv_61)\n",
    "\n",
    "# upconv_2 = layers.Conv2DTranspose(64*hyper_param_channels, (2,2), strides = (2,2))(conv_62)\n",
    "# upconv_2_conc = layers.concatenate([upconv_2, conv_32])\n",
    "# conv_71 = layers.Conv2D(64*hyper_param_channels,(3,3),activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(upconv_2_conc)\n",
    "# conv_72 = layers.Conv2D(64*hyper_param_channels,(3,3),activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv_71)\n",
    "\n",
    "# upconv_3 = layers.Conv2DTranspose(32*hyper_param_channels,(2,2), strides=(2,2))(conv_72)\n",
    "# upconv_3_conc = layers.concatenate([upconv_3,conv_22])\n",
    "# conv_81 = layers.Conv2D(32*hyper_param_channels,(3,3),activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(upconv_3_conc)\n",
    "# conv_82 = layers.Conv2D(32*hyper_param_channels,(3,3),activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv_81)\n",
    "\n",
    "# upconv_4 = layers.Conv2DTranspose(16*hyper_param_channels,(2,2), strides=(2,2))(conv_82)\n",
    "# upconv_4_conc = layers.concatenate([upconv_4,conv_12])\n",
    "# conv_91 = layers.Conv2D(16*hyper_param_channels,(3,3),activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(upconv_4_conc)\n",
    "# conv_92 = layers.Conv2D(16*hyper_param_channels,(3,3),activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv_91)\n",
    "# outputs = layers.Conv2D(1,(1,1), activation = 'sigmoid', padding = 'same',kernel_initializer = 'he_normal', bias_initializer=output_bias)(conv_92)#TODO: Check function here\n",
    "\n",
    "# model = tf.keras.Model(inputs = [inputs], outputs = [outputs])\n",
    "\n",
    "trained_model = tf.keras.models.load_model('./trainedModels/hptuning_24_04_19/hptuning_session2.h5')\n",
    "\n",
    "# Show the model architecture\n",
    "trained_model.summary()\n",
    "\n",
    "trained_model.trainable = False # Freeze the layers\n",
    "\n",
    "# Create a new model on top\n",
    "# inputs = tf.keras.layers.Input((IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))\n",
    "# outputs = trained_model(inputs)\n",
    "# model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# model.add(Dense(128, activation = \"relu\"))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(16, activation = \"relu\"))\n",
    "\n",
    "# model.add(Dense(1, activation = \"sigmoid\", bias_initializer=output_bias))\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))\n",
    "x = trained_model(inputs, training=False)\n",
    "# x = global_average_layer(x)   \n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "trained_model.trainable = False # Freeze the layers\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate = hyper_param_learning_rate)\n",
    "\n",
    "#Compiling model\n",
    "model.compile(optimizer=optimizer , loss='binary_crossentropy', metrics=['accuracy']) #TODO: Parameters check #metrics.BinaryIoU()\n",
    "model.summary()\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25, restore_best_weights=True)\n",
    "\n",
    "epochs = hyper_param_epochs  \n",
    "batch_size = hyper_param_batch_size\n",
    "\n",
    "# run_name = \"/run-%d\" % session_num\n",
    "# logdir = f\"logs/hparam_tuning_{date}/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + run_name\n",
    "# tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train_bin, \n",
    "                    epochs = epochs, \n",
    "                    validation_data = (X_val, y_val_bin), \n",
    "                    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                    callbacks=[early_stopping],\n",
    "                    batch_size = batch_size,) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 23ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.51%\n",
      "Precision: 0.8440\n",
      "Recall: 0.8364\n",
      "F1 Score: 0.8402\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming you have 'test_labels' and 'binary_predictions'\n",
    "# test_labels: True labels for the test set\n",
    "# binary_predictions: Predictions made by the model (0 or 1)\n",
    "\n",
    "Y_pred = model.predict(test_images)\n",
    "Y_pred_bin_list = []\n",
    "for val in Y_pred:\n",
    "    if val > 0.8:\n",
    "        Y_pred_bin_list.append(1)\n",
    "    else:\n",
    "        Y_pred_bin_list.append(0)\n",
    "Y_pred_bin = np.array(Y_pred_bin_list)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(test_masks_bin, Y_pred_bin)\n",
    "\n",
    "# Display the confusion matrix using a heatmap\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 16})\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Additional metrics\n",
    "accuracy = accuracy_score(test_masks_bin, Y_pred_bin)\n",
    "precision = precision_score(test_masks_bin, Y_pred_bin)\n",
    "recall = recall_score(test_masks_bin, Y_pred_bin)\n",
    "f1 = f1_score(test_masks_bin, Y_pred_bin)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning_24_04_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred = model.predict(test_images)\n",
    "\n",
    "# Model Loss\n",
    "plot_folder = f\"./plots/{date}\"\n",
    "os.makedirs(plot_folder, exist_ok=True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"],label = \"Train Loss\", color = \"black\")\n",
    "plt.plot(history.history[\"val_loss\"],label = \"Validation Loss\", color = \"darkred\", marker = \"+\", linestyle=\"dashed\", markeredgecolor = \"purple\", markeredgewidth = 2)\n",
    "plt.title(f\"Model Loss - session \", color = \"darkred\", size = 13)\n",
    "plt.legend()\n",
    "# plt.savefig(f\"plots/{date}/loss_session_{session_num}.png\")\n",
    "plt.close()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "model_folder = f\"./trainedModels/hptuning_{date}\"\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# model.save(f\"trainedModels/hptuning_{date}/hptuning_session{session_num}.h5\")\n",
    "\n",
    "# Model IoU score\n",
    "# threshold_list = [0.1, 0.2, 0.3, 0.4]\n",
    "threshold_list = np.linspace(0.1, 0.5, 20)\n",
    "jaccard_scores = []\n",
    "Y_pred = model.predict(test_images)\n",
    "true_masks_flat = test_masks.reshape(test_masks.shape[0], -1)\n",
    "for threshold in threshold_list:\n",
    "    y_pred_binary = (Y_pred >= threshold).astype(int)\n",
    "    pred_masks_binary_flat = y_pred_binary.reshape(y_pred_binary.shape[0], -1)\n",
    "    jaccard_scores.append(jaccard_score(true_masks_flat, pred_masks_binary_flat, average=\"micro\"))\n",
    "print(\"Best jacard score: \", max(jaccard_scores))\n",
    "\n",
    "accuracy = max(jaccard_scores)\n",
    "\n",
    "\n",
    "\n",
    "# model.fit(x_train, y_train, epochs=1) # Run with 1 epoch to speed things up for demo purposes\n",
    "# _, accuracy = model.evaluate(test_images, test_masks)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams, session_num, date):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams, session_num, date)\n",
    "    tf.summary.scalar(METRIC_F1SCORE, accuracy, step=1)\n",
    "    tf.summary.scalar('Run nr.', session_num, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "for channels in HP_CHANNELS.domain.values:\n",
    "  for image_size in HP_IMAGE_SIZE.domain.values:\n",
    "    for learning_rate in HP_LEARNING_RATE.domain.values:\n",
    "      for batch_size in HP_BATCH_SIZE.domain.values:\n",
    "        for epochs in HP_EPOCHS.domain.values:\n",
    "          hparams = {\n",
    "              HP_CHANNELS: channels,\n",
    "              HP_IMAGE_SIZE: image_size,\n",
    "              HP_LEARNING_RATE: learning_rate,\n",
    "              HP_BATCH_SIZE: batch_size,\n",
    "              HP_EPOCHS: epochs,\n",
    "          }\n",
    "          run_name = \"run-%d\" % session_num\n",
    "          print('--- Starting trial: %s' % run_name)\n",
    "          print({h.name: hparams[h] for h in hparams})\n",
    "          run(f\"logs/hparam_tuning_{date}/{run_name}\", hparams, session_num, date)\n",
    "          session_num += 1\n",
    "\n",
    "# HP_CHANNELS = hp.HParam('channels', hp.Discrete([1, 2]))\n",
    "# HP_LEARNING_RATE = hp.HParam('learning_rate', hp.RealInterval(0.0001, 0.01))  \n",
    "# HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([32, 64]))\n",
    "# HP_EPOCHS = hp.HParam('epochs', hp.Discrete([10, 20]))\n",
    "# HP_IMAGE_SIZE = hp.HParam('image_size', hp.Discrete([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning_24_04_18"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
